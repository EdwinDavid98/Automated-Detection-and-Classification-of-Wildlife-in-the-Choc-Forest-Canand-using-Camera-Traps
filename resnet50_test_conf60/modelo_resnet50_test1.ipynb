{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models import resnet50\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.progress import RichProgressBar\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchmetrics import AUROC, Accuracy, F1Score, Precision, Recall\n",
    "from torchmetrics.classification import MulticlassROC\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparámetros\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_WORKERS = 3\n",
    "TOTAL_CLASSES = 6\n",
    "CONFIDENCE_THRESHOLD = 0.60\n",
    "IMAGE_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas de los archivos Excel\n",
    "excel_paths = [\n",
    "    '/home/emontenegrob/dataset_frames_conf/dataset_frames_1_1.xlsx',\n",
    "    '/home/emontenegrob/dataset_frames_conf/dataset_frames_2_2.xlsx',\n",
    "    '/home/emontenegrob/dataset_frames_conf/dataset_frames_3_3.xlsx',\n",
    "    '/home/emontenegrob/dataset_frames_conf/dataset_frames_4_4.xlsx',\n",
    "    '/home/emontenegrob/dataset_frames_conf/dataset_frames_5_5.xlsx',\n",
    "    '/home/emontenegrob/dataset_frames_conf/dataset_frames_6_6.xlsx'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimalDataset(Dataset):\n",
    "    def __init__(self, excel_paths, partition, transform=None):\n",
    "        dataframes = [pd.read_excel(path) for path in excel_paths]\n",
    "        self.data = pd.concat(dataframes, ignore_index=True)\n",
    "        self.data = self.data[(self.data['Confianza'] > CONFIDENCE_THRESHOLD) & (self.data['Partition'] == partition)]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        image_path = row['Frame (imagen luego del algoritmo de detección de movimiento)']\n",
    "        bbox = row['Bounding Box']\n",
    "        label = row['ID']\n",
    "        \n",
    "        image = Image.open(image_path)\n",
    "        x1, y1, x2, y2 = eval(bbox)\n",
    "        image = image.crop((x1, y1, x2, y2))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimalDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, excel_paths, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS):\n",
    "        super().__init__()\n",
    "        self.excel_paths = excel_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.RandomCrop((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        self.test_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        self.train_dataset = AnimalDataset(self.excel_paths, partition='train', transform=self.train_transform)\n",
    "        self.val_dataset = AnimalDataset(self.excel_paths, partition='validation', transform=self.test_transform)\n",
    "        self.test_dataset = AnimalDataset(self.excel_paths, partition='test', transform=self.test_transform)\n",
    "        \n",
    "        print(f\"Tamaño del conjunto de entrenamiento: {len(self.train_dataset)}\")\n",
    "        print(f\"Tamaño del conjunto de validación: {len(self.val_dataset)}\")\n",
    "        print(f\"Tamaño del conjunto de prueba: {len(self.test_dataset)}\")\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample_images(data_module, logger, num_samples=2):\n",
    "    \"\"\"\n",
    "    Visualiza 'num_samples' imágenes por clase del conjunto de entrenamiento y las registra en TensorBoard.\n",
    "    \n",
    "    Args:\n",
    "    data_module (AnimalDataModule): El módulo de datos que contiene el dataset.\n",
    "    logger (TensorBoardLogger): El logger de TensorBoard.\n",
    "    num_samples (int): Número de muestras a visualizar por clase.\n",
    "    \"\"\"\n",
    "    if not hasattr(data_module, 'train_dataset'):\n",
    "        data_module.setup('fit')\n",
    "    \n",
    "    dataset = data_module.train_dataset\n",
    "    class_samples = {i: [] for i in range(TOTAL_CLASSES)}\n",
    "    \n",
    "    for idx in range(len(dataset)):\n",
    "        img, label = dataset[idx]\n",
    "        if len(class_samples[label]) < num_samples:\n",
    "            class_samples[label].append(img)\n",
    "        \n",
    "        if all(len(samples) == num_samples for samples in class_samples.values()):\n",
    "            break\n",
    "    \n",
    "    # Crear un grid de imágenes para cada clase\n",
    "    for class_idx, samples in class_samples.items():\n",
    "        # Convertir la lista de imágenes a un tensor\n",
    "        img_tensor = torch.stack(samples)\n",
    "        \n",
    "        # Crear un grid\n",
    "        img_grid = make_grid(img_tensor, nrow=num_samples, padding=2, normalize=True)\n",
    "        \n",
    "        # Registrar el grid en TensorBoard\n",
    "        logger.experiment.add_image(f'Sample Images Class {class_idx}', img_grid, dataformats='CHW')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_weights(data_module):\n",
    "    labels = []\n",
    "    for batch in data_module.train_dataloader():\n",
    "        _, label = batch\n",
    "        labels.extend(label.numpy())\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(labels), y=labels)\n",
    "    return torch.tensor(class_weights, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningResNet50(pl.LightningModule):\n",
    "    def __init__(self, learning_rate=LEARNING_RATE, num_classes=TOTAL_CLASSES, class_weights=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_classes = num_classes\n",
    "        self.class_weights = class_weights\n",
    "        \n",
    "        self.model = resnet50(pretrained=True)\n",
    "        num_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        \n",
    "        # Añadir estas líneas para inicializar las listas de historial\n",
    "        self.train_loss_history = []\n",
    "        self.val_loss_history = []\n",
    "        self.train_acc_history = []\n",
    "        self.val_acc_history = []\n",
    "\n",
    "        # Congelar todas las capas excepto las últimas\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.model.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in self.model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.test_acc = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "\n",
    "        self.train_f1 = F1Score(task=\"multiclass\", num_classes=self.num_classes, average='macro')\n",
    "        self.val_f1 = F1Score(task=\"multiclass\", num_classes=self.num_classes, average='macro')\n",
    "        self.test_f1 = F1Score(task=\"multiclass\", num_classes=self.num_classes, average='macro')\n",
    "\n",
    "        self.train_precision = Precision(task=\"multiclass\", num_classes=self.num_classes, average='macro')\n",
    "        self.val_precision = Precision(task=\"multiclass\", num_classes=self.num_classes, average='macro')\n",
    "        self.test_precision = Precision(task=\"multiclass\", num_classes=self.num_classes, average='macro')\n",
    "\n",
    "        self.train_recall = Recall(task=\"multiclass\", num_classes=self.num_classes, average='macro')\n",
    "        self.val_recall = Recall(task=\"multiclass\", num_classes=self.num_classes, average='macro')\n",
    "        self.test_recall = Recall(task=\"multiclass\", num_classes=self.num_classes, average='macro')\n",
    "\n",
    "        self.train_auc = AUROC(task=\"multiclass\", num_classes=self.num_classes, average='macro')\n",
    "        self.val_auc = AUROC(task=\"multiclass\", num_classes=self.num_classes, average='macro')\n",
    "        self.test_auc = AUROC(task=\"multiclass\", num_classes=self.num_classes, average='macro')\n",
    "\n",
    "        self.test_roc = MulticlassROC(num_classes=self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def _shared_step(self, batch):\n",
    "        images, labels = batch\n",
    "        class_weights = self.class_weights.to(self.device)\n",
    "        logits = self(images)\n",
    "        loss = nn.CrossEntropyLoss(weight=class_weights)(logits, labels)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        return loss, probs, labels\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, probs, labels = self._shared_step(batch)\n",
    "        acc = self.train_acc(probs, labels)\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "        self.log('train_acc', acc, on_step=False, on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "        self.log('train_f1', self.train_f1(probs, labels), on_step=False, on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "        self.log('train_precision', self.train_precision(probs, labels), on_step=False, on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "        self.log('train_recall', self.train_recall(probs, labels), on_step=False, on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "        self.log('train_auc', self.train_auc(probs, labels), on_step=False, on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, probs, labels = self._shared_step(batch)\n",
    "        acc = self.val_acc(probs, labels)\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "        self.log('val_acc', acc, on_step=False, on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "        self.log('val_f1', self.val_f1(probs, labels), on_step=False, on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "        self.log('val_precision', self.val_precision(probs, labels), on_step=False, on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "        self.log('val_recall', self.val_recall(probs, labels), on_step=False, on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "        self.log('val_auc', self.val_auc(probs, labels), on_step=False, on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "\n",
    "    def on_fit_start(self):\n",
    "        # Registrar la estructura del modelo en TensorBoard\n",
    "        self.logger.experiment.add_graph(self, torch.rand(1, 3, 224, 224).to(self.device))\n",
    "        \n",
    "        # Visualizar muestras de imágenes\n",
    "        visualize_sample_images(self.trainer.datamodule, self.logger)\n",
    "        \n",
    "    def on_test_epoch_start(self):\n",
    "        self.test_step_outputs = []\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, probs, labels = self._shared_step(batch)\n",
    "        self.log('test_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('test_acc', self.test_acc(probs, labels), on_step=False, on_epoch=True)\n",
    "        self.log('test_f1', self.test_f1(probs, labels), on_step=False, on_epoch=True)\n",
    "        self.log('test_precision', self.test_precision(probs, labels), on_step=False, on_epoch=True)\n",
    "        self.log('test_recall', self.test_recall(probs, labels), on_step=False, on_epoch=True)\n",
    "        self.log('test_auc', self.test_auc(probs, labels), on_step=False, on_epoch=True)\n",
    "        self.test_roc.update(probs, labels)\n",
    "        \n",
    "        output = {'loss': loss, 'probs': probs, 'labels': labels}\n",
    "        self.test_step_outputs.append(output)\n",
    "        return output\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        # Acumular los valores de pérdida y precisión\n",
    "        train_loss = self.trainer.callback_metrics['train_loss'].cpu().item()\n",
    "        val_loss = self.trainer.callback_metrics['val_loss'].cpu().item()\n",
    "        train_acc = self.trainer.callback_metrics['train_acc'].cpu().item()\n",
    "        val_acc = self.trainer.callback_metrics['val_acc'].cpu().item()\n",
    "\n",
    "        self.train_loss_history.append(train_loss)\n",
    "        self.val_loss_history.append(val_loss)\n",
    "        self.train_acc_history.append(train_acc)\n",
    "        self.val_acc_history.append(val_acc)\n",
    "\n",
    "    def on_fit_end(self):\n",
    "        # Crear gráficos de pérdida y precisión al final del entrenamiento\n",
    "        epochs = range(len(self.train_loss_history))\n",
    "\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        \n",
    "        # Gráfico de pérdida\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.plot(epochs, self.train_loss_history, 'b-', label='Train Loss')\n",
    "        plt.plot(epochs, self.val_loss_history, 'r-', label='Validation Loss')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        # Gráfico de precisión\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.plot(epochs, self.train_acc_history, 'b-', label='Train Accuracy')\n",
    "        plt.plot(epochs, self.val_acc_history, 'r-', label='Validation Accuracy')\n",
    "        plt.title('Training and Validation Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Guardar la figura en TensorBoard\n",
    "        self.logger.experiment.add_figure('Training History', plt.gcf())\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        # Recopilación de todas las predicciones y etiquetas\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        for output in self.test_step_outputs:\n",
    "            all_preds.extend(output['probs'].cpu().numpy())\n",
    "            all_labels.extend(output['labels'].cpu().numpy())\n",
    "\n",
    "        all_preds = np.array(all_preds)\n",
    "        all_labels = np.array(all_labels)\n",
    "\n",
    "        # Binarizar las etiquetas\n",
    "        all_labels_bin = label_binarize(all_labels, classes=list(range(self.num_classes)))\n",
    "        \n",
    "        # Calcular AUC-ROC para cada clase\n",
    "        fpr = {}\n",
    "        tpr = {}\n",
    "        roc_auc = {}\n",
    "        for i in range(self.num_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(all_labels_bin[:, i], all_preds[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        # Calcular AUC-ROC micro y macro\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(all_labels_bin.ravel(), all_preds.ravel())\n",
    "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "        fpr[\"macro\"] = np.unique(np.concatenate([fpr[i] for i in range(self.num_classes)]))\n",
    "        tpr[\"macro\"] = np.zeros_like(fpr[\"macro\"])\n",
    "        for i in range(self.num_classes):\n",
    "            tpr[\"macro\"] += np.interp(fpr[\"macro\"], fpr[i], tpr[i])\n",
    "        tpr[\"macro\"] /= self.num_classes\n",
    "        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "        # Crear la gráfica ROC\n",
    "        plt.figure(figsize=(14, 10))\n",
    "\n",
    "        plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "                 label='Micro-average ROC curve (area = {0:0.2f})'\n",
    "                       ''.format(roc_auc[\"micro\"]),\n",
    "                 color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "        plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "                 label='Macro-average ROC curve (area = {0:0.2f})'\n",
    "                       ''.format(roc_auc[\"macro\"]),\n",
    "                 color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "        for i in range(self.num_classes):\n",
    "            plt.plot(fpr[i], tpr[i], lw=2,\n",
    "                     label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                     ''.format(i, roc_auc[i]))\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        \n",
    "        plt.xlabel('False Positive Rate', fontsize=14)\n",
    "        plt.ylabel('True Positive Rate', fontsize=14)\n",
    "        plt.title('Receiver Operating Characteristic to Multi-Class', fontsize=16)\n",
    "        plt.legend(loc=\"lower right\", fontsize=10)\n",
    "\n",
    "        # Guardar la figura en TensorBoard\n",
    "        self.logger.experiment.add_figure('ROC Curve', plt.gcf())\n",
    "\n",
    "        # Cerrar la figura para liberar memoria\n",
    "        plt.close()\n",
    "\n",
    "        # Calcular y registrar el classification report\n",
    "        all_preds_class = all_preds.argmax(axis=1)\n",
    "        report = classification_report(all_labels, all_preds_class, output_dict=True)\n",
    "        \n",
    "        # Convertir el reporte a un DataFrame\n",
    "        df_report = pd.DataFrame(report).transpose()\n",
    "        \n",
    "        # Renombrar el índice para mayor claridad\n",
    "        df_report.index.name = 'Class'\n",
    "        df_report.reset_index(inplace=True)\n",
    "        \n",
    "        # Redondear los valores numéricos a 3 decimales\n",
    "        df_report = df_report.round(3)\n",
    "        \n",
    "        # Crear una tabla estilizada\n",
    "        table = tabulate(df_report, headers='keys', tablefmt='pretty', showindex=False)\n",
    "        \n",
    "        # Registrar la tabla en TensorBoard como texto\n",
    "        self.logger.experiment.add_text('Classification Report', f'<pre>{table}</pre>')\n",
    "        \n",
    "        # También puedes guardar la tabla como una imagen si lo prefieres\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        ax.axis('off')\n",
    "        ax.table(cellText=df_report.values,\n",
    "                 colLabels=df_report.columns,\n",
    "                 cellLoc='center',\n",
    "                 loc='center')\n",
    "        plt.title('Classification Report')\n",
    "        self.logger.experiment.add_figure('Classification Report Table', fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Visualizar el classification report como un heatmap\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(df_report.iloc[:, 1:5], annot=True, cmap='YlGnBu')\n",
    "        plt.title('Classification Report Heatmap')\n",
    "        self.logger.experiment.add_figure('Classification Report Heatmap', plt.gcf())\n",
    "        plt.close()\n",
    "        \n",
    "        # Calcular la matriz de confusión\n",
    "        cm = confusion_matrix(all_labels, all_preds_class)\n",
    "        \n",
    "        # Crear una figura para la matriz de confusión\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted Labels')\n",
    "        plt.ylabel('True Labels')\n",
    "        self.logger.experiment.add_figure('Confusion Matrix', plt.gcf())\n",
    "        plt.close()\n",
    "\n",
    "        # Calcular la matriz de confusión normalizada\n",
    "        cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "        # Crear una figura para la matriz de confusión normalizada\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues')\n",
    "        plt.title('Normalized Confusion Matrix')\n",
    "        plt.xlabel('Predicted Labels')\n",
    "        plt.ylabel('True Labels')\n",
    "        self.logger.experiment.add_figure('Normalized Confusion Matrix', plt.gcf())\n",
    "        plt.close()\n",
    "\n",
    "        # Limpiar los outputs para la siguiente época\n",
    "        self.test_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def on_fit_start(self):\n",
    "        # Registrar la estructura del modelo en TensorBoard\n",
    "        self.logger.experiment.add_graph(self, torch.rand(1, 3, 224, 224).to(self.device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 20931\n",
      "Tamaño del conjunto de validación: 3796\n",
      "Tamaño del conjunto de prueba: 4705\n"
     ]
    }
   ],
   "source": [
    "# Inicializar el DataModule\n",
    "data_module = AnimalDataModule(excel_paths)\n",
    "data_module.setup(stage='fit')\n",
    "\n",
    "# Calcular los pesos de clase\n",
    "class_weights = calculate_class_weights(data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Configurar el logger de TensorBoard\n",
    "logger = TensorBoardLogger(\"tb_logs_resnet50\", name=\"resnet50_animals_jocotoco_conf60\")\n",
    "\n",
    "# Inicializar el modelo\n",
    "lightning_model = LightningResNet50(learning_rate=LEARNING_RATE, num_classes=TOTAL_CLASSES, class_weights=class_weights)\n",
    "\n",
    "# Configurar los callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='checkpoints_resnet50',\n",
    "    filename='resnet50-{epoch:02d}-{val_loss:.2f}',\n",
    "    save_top_k=3,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "progress_bar_callback = RichProgressBar()\n",
    "\n",
    "# Configurar el Trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=NUM_EPOCHS,\n",
    "    callbacks=[checkpoint_callback, early_stopping_callback, progress_bar_callback],\n",
    "    accelerator='gpu',\n",
    "    devices=1,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=50,\n",
    "    deterministic=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/emontenegrob/codigo_solo_tesis_resnet50_testq_conf60/checkpoints_resnet50 exists and is not empty.\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 20931\n",
      "Tamaño del conjunto de validación: 3796\n",
      "Tamaño del conjunto de prueba: 4705\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name            </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0  </span>│ model           │ ResNet              │ 23.5 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1  </span>│ train_acc       │ MulticlassAccuracy  │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2  </span>│ val_acc         │ MulticlassAccuracy  │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3  </span>│ test_acc        │ MulticlassAccuracy  │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4  </span>│ train_f1        │ MulticlassF1Score   │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5  </span>│ val_f1          │ MulticlassF1Score   │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6  </span>│ test_f1         │ MulticlassF1Score   │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7  </span>│ train_precision │ MulticlassPrecision │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8  </span>│ val_precision   │ MulticlassPrecision │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9  </span>│ test_precision  │ MulticlassPrecision │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 10 </span>│ train_recall    │ MulticlassRecall    │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 11 </span>│ val_recall      │ MulticlassRecall    │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 12 </span>│ test_recall     │ MulticlassRecall    │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 13 </span>│ train_auc       │ MulticlassAUROC     │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 14 </span>│ val_auc         │ MulticlassAUROC     │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 15 </span>│ test_auc        │ MulticlassAUROC     │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 16 </span>│ test_roc        │ MulticlassROC       │      0 │ train │\n",
       "└────┴─────────────────┴─────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName           \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType               \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0 \u001b[0m\u001b[2m \u001b[0m│ model           │ ResNet              │ 23.5 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1 \u001b[0m\u001b[2m \u001b[0m│ train_acc       │ MulticlassAccuracy  │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2 \u001b[0m\u001b[2m \u001b[0m│ val_acc         │ MulticlassAccuracy  │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3 \u001b[0m\u001b[2m \u001b[0m│ test_acc        │ MulticlassAccuracy  │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4 \u001b[0m\u001b[2m \u001b[0m│ train_f1        │ MulticlassF1Score   │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m5 \u001b[0m\u001b[2m \u001b[0m│ val_f1          │ MulticlassF1Score   │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m6 \u001b[0m\u001b[2m \u001b[0m│ test_f1         │ MulticlassF1Score   │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m7 \u001b[0m\u001b[2m \u001b[0m│ train_precision │ MulticlassPrecision │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m8 \u001b[0m\u001b[2m \u001b[0m│ val_precision   │ MulticlassPrecision │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m9 \u001b[0m\u001b[2m \u001b[0m│ test_precision  │ MulticlassPrecision │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m10\u001b[0m\u001b[2m \u001b[0m│ train_recall    │ MulticlassRecall    │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m11\u001b[0m\u001b[2m \u001b[0m│ val_recall      │ MulticlassRecall    │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m12\u001b[0m\u001b[2m \u001b[0m│ test_recall     │ MulticlassRecall    │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m13\u001b[0m\u001b[2m \u001b[0m│ train_auc       │ MulticlassAUROC     │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m14\u001b[0m\u001b[2m \u001b[0m│ val_auc         │ MulticlassAUROC     │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m15\u001b[0m\u001b[2m \u001b[0m│ test_auc        │ MulticlassAUROC     │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m16\u001b[0m\u001b[2m \u001b[0m│ test_roc        │ MulticlassROC       │      0 │ train │\n",
       "└────┴─────────────────┴─────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 15.0 M                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 8.5 M                                                                                        \n",
       "<span style=\"font-weight: bold\">Total params</span>: 23.5 M                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 94                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 167                                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 15.0 M                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 8.5 M                                                                                        \n",
       "\u001b[1mTotal params\u001b[0m: 23.5 M                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 94                                                                         \n",
       "\u001b[1mModules in train mode\u001b[0m: 167                                                                                         \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4642c221492483795967556f0addf2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is \n",
       "incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
       "  self.pid = os.fork()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is \n",
       "incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
       "  self.pid = os.fork()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: TorchMetricsUserWarning: You are \n",
       "trying to use a metric in deterministic mode on GPU that uses `torch.cumsum`, which is currently not supported. The\n",
       "tensor will be copied to the CPU memory to compute it and then copied back to GPU. Expect some slowdowns.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: TorchMetricsUserWarning: You are \n",
       "trying to use a metric in deterministic mode on GPU that uses `torch.cumsum`, which is currently not supported. The\n",
       "tensor will be copied to the CPU memory to compute it and then copied back to GPU. Expect some slowdowns.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in \n",
       "targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in \n",
       "targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in \n",
       "targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in \n",
       "targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "trainer.fit(lightning_model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo guardado en: /home/emontenegrob/codigo_solo_tesis_resnet50_testq_conf60/checkpoints_resnet50/resnet50-epoch=18-val_loss=0.09.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Cargar el mejor modelo\n",
    "best_model_path = checkpoint_callback.best_model_path\n",
    "best_model = LightningResNet50.load_from_checkpoint(best_model_path)\n",
    "print(f\"Mejor modelo guardado en: {best_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 20931\n",
      "Tamaño del conjunto de validación: 3796\n",
      "Tamaño del conjunto de prueba: 4705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f30176e47ef4930be229da0e8152a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: TorchMetricsUserWarning: You are \n",
       "trying to use a metric in deterministic mode on GPU that uses `torch.cumsum`, which is currently not supported. The\n",
       "tensor will be copied to the CPU memory to compute it and then copied back to GPU. Expect some slowdowns.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: TorchMetricsUserWarning: You are \n",
       "trying to use a metric in deterministic mode on GPU that uses `torch.cumsum`, which is currently not supported. The\n",
       "tensor will be copied to the CPU memory to compute it and then copied back to GPU. Expect some slowdowns.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in \n",
       "targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in \n",
       "targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in \n",
       "targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in \n",
       "targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.950478196144104     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_auc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01129637099802494    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_f1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8366580009460449     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.14273853600025177    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8500422239303589     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8287150859832764     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.950478196144104    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_auc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01129637099802494   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_f1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8366580009460449    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.14273853600025177   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8500422239303589    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8287150859832764    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.14273853600025177,\n",
       "  'test_acc': 0.950478196144104,\n",
       "  'test_f1': 0.8366580009460449,\n",
       "  'test_precision': 0.8500422239303589,\n",
       "  'test_recall': 0.8287150859832764,\n",
       "  'test_auc': 0.01129637099802494}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluación en el conjunto de prueba\n",
    "trainer.test(model=best_model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        (async () => {\n            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n            url.searchParams.set('tensorboardColab', 'true');\n            const iframe = document.createElement('iframe');\n            iframe.src = url;\n            iframe.setAttribute('width', '100%');\n            iframe.setAttribute('height', '800');\n            iframe.setAttribute('frameborder', 0);\n            document.body.appendChild(iframe);\n        })();\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualización de TensorBoard (si estás ejecutando en un notebook)\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir tb_logs_resnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
