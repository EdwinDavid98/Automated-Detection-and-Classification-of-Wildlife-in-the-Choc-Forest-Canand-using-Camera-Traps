# Sistema de Monitoreo Autom√°tico de Fauna Silvestre en el Bosque del Choc√≥ ü¶Å üå≥
## Descripci√≥n
Este proyecto implementa un sistema de visi√≥n artificial de √∫ltima generaci√≥n para la detecci√≥n y clasificaci√≥n autom√°tica de especies en la Reserva Jocotoco Canand√©, una de las regiones m√°s biodiversas del planeta. Utilizando una arquitectura dual que combina modelos YOLO para detecci√≥n y redes neuronales profundas (ResNet50 y MobileNetV3) para clasificaci√≥n, el sistema procesa videos de c√°maras trampa para identificar y monitorear seis especies nativas:
- ü¶ä Agut√≠ Centroamericano
- üêøÔ∏è Ardillas
- ü¶° Armadillo de Nueve Bandas
- ü¶´ Paca de Tierras Bajas
- üêÄ Roedores
- ü¶É Tinam√∫ Grande

El sistema alcanza un F1-score ponderado de 0.951, demostrando su efectividad para el monitoreo automatizado de biodiversidad. Esta herramienta representa un avance significativo en la conservaci√≥n de especies, permitiendo a investigadores y conservacionistas procesar grandes vol√∫menes de datos de manera eficiente y precisa.
Desarrollado como parte de una iniciativa para modernizar las pr√°cticas de conservaci√≥n en el Choc√≥ ecuatoriano, este proyecto establece un precedente para la implementaci√≥n de tecnolog√≠as de inteligencia artificial en la protecci√≥n de ecosistemas cr√≠ticos.

## üîÑPipeline del Sistema 

El sistema implementa un enfoque de dos etapas para el procesamiento de videos de c√°maras trampa:

### üì∏ Fase 1: Detecci√≥n de Objetos

- Preprocesamiento: Extracci√≥n de frames de videos con resoluci√≥n 640x368 p√≠xeles

- Detecci√≥n:

   - YOLOv5l: Detecci√≥n general con umbral de confianza >55%

   - YOLOv8x: Implementado espec√≠ficamente para especies nocturnas y de dif√≠cil detecci√≥n

- Extracci√≥n: Hasta 350 frames por video con sus respectivos bounding boxes

### üîç Fase 2: Clasificaci√≥n de Especies

- Modelos Implementados:

  - ResNet50: Optimizado para m√°xima precisi√≥n

  - MobileNetV3: Dise√±ado para eficiencia computacional

- T√©cnicas de Mejora:

Transfer Learning con pesos preentrenados de ImageNet

Data Augmentation (RandomCrop, RandomHorizontalFlip, RandomRotation, ColorJitter)

Manejo de desbalance de clases mediante pesos adaptativos

![diagram 2 more big](https://github.com/user-attachments/assets/11e59021-bb86-4e25-a773-b526bc11915d)

## üìä Dataset
  
El conjunto de datos consta de 780 videos de c√°maras trampa (130 por cada una de las seis especies objetivo) capturados en la Reserva Jocotoco Canand√©. Los datos se dividieron en tres conjuntos: 70% para entrenamiento, 15% para validaci√≥n y 15% para pruebas. El procesamiento mediante detectores YOLO result√≥ en aproximadamente 33,000 frames relevantes, proporcionando una base s√≥lida para el entrenamiento y evaluaci√≥n de los modelos de clasificaci√≥n.

## üìã Requisitos
- torch>=2.3.0
- torchvision>=0.18.0
- pytorch-lightning>=2.4.0
- ultralytics>=8.2.81
- opencv-python>=4.8.0
- pandas>=2.0.3
- numpy>=1.25.2
- Pillow>=9.4.0
- scikit-learn>=1.2.2
- matplotlib>=3.7.1
- seaborn>=0.13.1
- torchmetrics>=1.4.1
## ‚öôÔ∏è Instalaci√≥n

```
# Clonar repositorio
git clone [URL del repositorio]

# Instalar dependencias
pip install -r requirements.txt
```
## üíª Requisitos de Hardware
- CUDA 12.1 compatible
- RAM: 32GB recomendado
- GPU: NVIDIA (8GB VRAM recomendado)
  
## üöÄ Uso
### 1. Instalaci√≥n de Requisitos
Aseg√∫rese de tener todas las dependencias necesarias instaladas con las versiones especificadas.

```
# Clonar repositorio
pip install -r requirements.txt
```
### 2. Detecci√≥n de Frames en Videos
El primer paso consiste en procesar los videos mediante el detector YOLO para extraer frames relevantes:
```
# Configuraci√≥n del detector YOLO
from ultralytics import YOLO

# Cargar el modelo
model = YOLO('yolov8x.pt')  # o 'yolov5l.pt'

# Configurar par√°metros
conf_threshold = 0.55  # Umbral de confianza >55%
max_frames = 350      # Frames m√°ximos por video

# Ejecutar detecci√≥n
results = model(video_path, conf=conf_threshold)
```
Este proceso generar√° un dataset de frames con sus respectivos bounding boxes para cada especie detectada.
### 3. Clasificaci√≥n de Especies
Una vez obtenidos los frames, se procede con el entrenamiento del clasificador:
```
# Configuraci√≥n del modelo de clasificaci√≥n
from pytorch_lightning import Trainer

# Definir hiperpar√°metros
hyperparameters = {
    'learning_rate': 0.0001,
    'batch_size': 32,
    'max_epochs': 100,
    'early_stopping': 10
}

# Iniciar entrenamiento con monitoreo
trainer = Trainer(
    max_epochs=hyperparameters['max_epochs'],
    accelerator='gpu',
    logger=TensorBoardLogger('logs/'),
    callbacks=[EarlyStopping(monitor='val_loss', patience=10)]
)
```
### 4. Monitoreo y Evaluaci√≥n
Los resultados del entrenamiento pueden visualizarse en tiempo real mediante TensorBoard:
```
tensorboard --logdir=logs/
```
En la interfaz de TensorBoard podr√° monitorear:
Acceder a http://localhost:6006 para visualizar:

- Evoluci√≥n del entrenamiento
- M√©tricas de rendimiento por especie
- Visualizaciones de matrices de confusi√≥n
- Curvas ROC para evaluaci√≥n de rendimiento
## üìä Resultados
